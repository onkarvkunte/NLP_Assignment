{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m3_assignment_part_III.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onkarvkunte/NLP_Assignment/blob/main/scripts/assignment_4_part_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III\n",
        "Using the previous two tutorials, please answer the following using an encorder-decoder approach and an LSTM compared approach.\n",
        "\n",
        "Please create a transformer-based classifier for English name classification into male or female.\n",
        "\n",
        "There are several datasets for name for male or female classification. In subseuqent iterations, this could be expanded to included more classifications.\n",
        "\n",
        "Below is the source from NLTK, which only has male and female available but could be used for the purposes of this assignment.\n",
        "\n",
        "```\n",
        "names = nltk.corpus.names\n",
        "names.fileids()\n",
        "['female.txt', 'male.txt']\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "[w for w in male_names if w in female_names]\n",
        "['Abbey', 'Abbie', 'Abby', 'Addie', 'Adrian', 'Adrien', 'Ajay', 'Alex', 'Alexis',\n",
        "'Alfie', 'Ali', 'Alix', 'Allie', 'Allyn', 'Andie', 'Andrea', 'Andy', 'Angel',\n",
        "'Angie', 'Ariel', 'Ashley', 'Aubrey', 'Augustine', 'Austin', 'Averil', ...]\n",
        "```"
      ],
      "metadata": {
        "id": "QD5ia2HsZpsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKQa86RpY5rH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data\n",
        "names = nltk.corpus.names\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "data = [(name, 0) for name in male_names] + [(name, 1) for name in female_names]\n",
        "\n",
        "# Data Preprocessing\n",
        "names, labels = zip(*data)\n",
        "vocab = set(' '.join(names))\n",
        "char_to_index = {char: idx for idx, char in enumerate(vocab)}\n",
        "max_seq_length = max(len(name) for name in names)\n",
        "data_encoded = np.array([[char_to_index[char] for char in name] for name in names])\n",
        "data_padded = tf.keras.preprocessing.sequence.pad_sequences(data_encoded, maxlen=max_seq_length)\n",
        "\n",
        "# Splitting Data\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(data_padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transformer-Based Classifier\n",
        "transformer_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=128, input_length=max_seq_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "transformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "transformer_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=10)\n",
        "\n",
        "# LSTM-Based Classifier\n",
        "lstm_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=128, input_length=max_seq_length),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "1. https://arxiv.org/pdf/2102.03692.pdf\n",
        "2. https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/exercise/13-attention.html\n",
        "3. https://towardsdatascience.com/deep-learning-gender-from-name-lstm-recurrent-neural-networks-448d64553044\n",
        "4. https://www.nltk.org/book/ch02.html#sec-lexical-resources"
      ],
      "metadata": {
        "id": "ExMITGgCdQWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PHiDsdXLhbbW"
      }
    }
  ]
}